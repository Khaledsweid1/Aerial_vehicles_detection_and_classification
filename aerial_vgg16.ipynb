{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TtFU79uRkNT",
        "outputId": "8ce187a6-0db3-4d3f-af1b-028c304d2186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 350 images belonging to 5 classes.\n",
            "Found 75 images belonging to 5 classes.\n",
            "Found 76 images belonging to 5 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/15\n",
            "11/11 [==============================] - 195s 17s/step - loss: 1.4095 - accuracy: 0.4114 - val_loss: 0.8098 - val_accuracy: 0.6800\n",
            "Epoch 2/15\n",
            "11/11 [==============================] - 101s 9s/step - loss: 0.7605 - accuracy: 0.7114 - val_loss: 0.5447 - val_accuracy: 0.8133\n",
            "Epoch 3/15\n",
            "11/11 [==============================] - 101s 9s/step - loss: 0.5260 - accuracy: 0.8000 - val_loss: 0.4857 - val_accuracy: 0.8267\n",
            "Epoch 4/15\n",
            "11/11 [==============================] - 101s 9s/step - loss: 0.4350 - accuracy: 0.8514 - val_loss: 0.4065 - val_accuracy: 0.8267\n",
            "Epoch 5/15\n",
            "11/11 [==============================] - 100s 9s/step - loss: 0.3239 - accuracy: 0.9029 - val_loss: 0.4039 - val_accuracy: 0.8933\n",
            "Epoch 6/15\n",
            "11/11 [==============================] - 100s 9s/step - loss: 0.2809 - accuracy: 0.9286 - val_loss: 0.3570 - val_accuracy: 0.8800\n",
            "Epoch 7/15\n",
            "11/11 [==============================] - 100s 9s/step - loss: 0.2698 - accuracy: 0.9114 - val_loss: 0.3723 - val_accuracy: 0.8933\n",
            "Epoch 8/15\n",
            "11/11 [==============================] - 100s 9s/step - loss: 0.2504 - accuracy: 0.9114 - val_loss: 0.3683 - val_accuracy: 0.8800\n",
            "Epoch 9/15\n",
            "11/11 [==============================] - 100s 9s/step - loss: 0.2338 - accuracy: 0.9229 - val_loss: 0.3297 - val_accuracy: 0.9067\n",
            "Epoch 10/15\n",
            "11/11 [==============================] - 100s 9s/step - loss: 0.1888 - accuracy: 0.9600 - val_loss: 0.3531 - val_accuracy: 0.8800\n",
            "Epoch 11/15\n",
            "11/11 [==============================] - 100s 9s/step - loss: 0.1912 - accuracy: 0.9400 - val_loss: 0.3270 - val_accuracy: 0.8933\n",
            "Epoch 12/15\n",
            "11/11 [==============================] - 100s 9s/step - loss: 0.1551 - accuracy: 0.9600 - val_loss: 0.2983 - val_accuracy: 0.9067\n",
            "Epoch 13/15\n",
            "11/11 [==============================] - 100s 9s/step - loss: 0.1326 - accuracy: 0.9714 - val_loss: 0.3655 - val_accuracy: 0.8800\n",
            "Epoch 14/15\n",
            "11/11 [==============================] - 101s 9s/step - loss: 0.1775 - accuracy: 0.9429 - val_loss: 0.2682 - val_accuracy: 0.9067\n",
            "Epoch 15/15\n",
            "11/11 [==============================] - 100s 9s/step - loss: 0.1364 - accuracy: 0.9686 - val_loss: 0.2545 - val_accuracy: 0.9200\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Set dataset path\n",
        "dataset_path = \"/content/drive/My Drive/Aerial classes small\"\n",
        "\n",
        "# Image Data Generators for train, validation, and test\n",
        "train_dir = os.path.join(dataset_path, 'train')\n",
        "val_dir = os.path.join(dataset_path, 'val')\n",
        "test_dir = os.path.join(dataset_path, 'test')\n",
        "\n",
        "img_size = (224, 224)  # VGG16 expects 224x224 images\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Load the VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze base layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(5, activation='softmax')(x)  # Output layer with 5 classes\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 15\n",
        "history = model.fit(train_gen, validation_data=val_gen, epochs=epochs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model (architecture + weights)\n",
        "model.save('vgg16_model.h5')\n",
        "print(\"Model saved locally as vgg16_model.h5\")\n",
        "\n",
        "# Download the entire model file\n",
        "from google.colab import files\n",
        "files.download('vgg16_model.h5')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "FD5izT6GZNTj",
        "outputId": "d70bfeaf-2239-45d1-f607-51723cb733e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved locally as vgg16_model.h5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f049cc41-b335-41cc-82b5-1aaf5d9d2f1c\", \"vgg16_model.h5\", 136037944)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}